{"files":[{"id":"3a150716-5dcf-40ee-b1cf-c10b6a109012","name":"appsscript","type":"json","source":"{\n  \"timeZone\": \"Asia/Kolkata\",\n  \"dependencies\": {\n  },\n  \"exceptionLogging\": \"STACKDRIVER\",\n  \"runtimeVersion\": \"V8\"\n}"},{"id":"fd8e13b1-d4a5-48bd-8d52-ca377adff18c","name":"Code","type":"server_js","source":"// function fetchOpenAICompletion(prompt) {\n//   var apiKey \u003d \u0027AIzaSyADr7aNKyEY07_LXvYi_iZF2qMwuN-7_XA\u0027; // Replace this with your OpenAI API key\n//   var apiUrl \u003d \u0027https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key\u003dAIzaSyADr7aNKyEY07_LXvYi_iZF2qMwuN-7_XA\u0027;\n\n//   // Setup the payload for the POST request\n//   var payload \u003d JSON.stringify({\n//     model: \"gemini-pro\", // Model to use\n//     prompt: prompt, // Dynamic prompt passed to the function\n//     max_tokens: 500, // Limit the maximum number of tokens\n//     temperature: 0.7 // Control the randomness (optional, adjust as needed)\n//   });\n\n//   // Setup the request options, including headers for authorization\n//   var options \u003d {\n//     method: \"post\",\n//     contentType: \"application/json\",\n//     payload: payload,\n//     headers: {\n//       Authorization: \"Bearer \" + apiKey\n//     },\n//     muteHttpExceptions: true // To handle errors more gracefully\n//   };\n\n//   // Try to fetch the completion from OpenAI\n//   try {\n//     var response \u003d UrlFetchApp.fetch(apiUrl, options);\n//     var jsonResponse \u003d JSON.parse(response.getContentText());\n    \n//     // Assuming the API call was successful and we got a response\n//     if (response.getResponseCode() \u003d\u003d\u003d 200) {\n//       var completionText \u003d jsonResponse.choices[0].text;\n//       var tokenUsage \u003d String(jsonResponse.usage.total_tokens); // Convert token usage to string\n//       return [completionText, tokenUsage]; // Return the desired information in an array\n//     } else {\n//       // Handle HTTP errors (e.g., rate limits, invalid requests)\n//       console.error(\"Error fetching OpenAI completion:\", jsonResponse);\n//       return [\"Error: \" + jsonResponse.error.message, \"0\"];\n//     }\n//   } catch (error) {\n//     // Catch and log any errors in the try block or with fetching\n//     console.error(\"Error in try-catch:\", error.toString());\n//     return [\"Error\", \"0\"]; // Return a default error array\n//   }\n// }\n\nfunction fetchGeminiAICompletion(prompt) {\n  // Replace with your actual Google Cloud Platform (GCP) project API key\n  const apiKey \u003d \u0027AIzaSyADr7aNKyEY07_LXvYi_iZF2qMwuN-7_XA\u0027;\n  const apiUrl \u003d \u0027https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key\u003d\u0027 + apiKey;\n\n  // Setup the payload for the POST request\n  const payload \u003d JSON.stringify({\n    model: \"gemini-pro\", // Model to use\n    prompt: prompt, // Dynamic prompt passed to the function\n    max_tokens: 500, // Limit the maximum number of tokens\n    temperature: 0.7 // Control the randomness (optional, adjust as needed)\n  });\n\n  // Setup the request options, including headers for authorization\n  const options \u003d {\n    method: \"post\",\n    contentType: \"application/json\",\n    payload: payload,\n    headers: {\n      Authorization: \"Bearer \" + apiKey\n    }\n  };\n\n  // Make the asynchronous fetch request for better performance\n  return fetch(apiUrl, options)\n    .then(response \u003d\u003e response.json())\n    .then(jsonResponse \u003d\u003e {\n      if (response.ok) { // Handle successful response (status code 200)\n        const completionText \u003d jsonResponse.choices[0].text;\n        const tokenUsage \u003d String(jsonResponse.usage.total_tokens);\n        return [completionText, tokenUsage];\n      } else {\n        // Handle HTTP errors (e.g., rate limits, invalid requests)\n        console.error(\"Error fetching Gemini AI completion:\", jsonResponse);\n        return [\"Error: \" + jsonResponse.error.message, \"0\"];\n      }\n    })\n    .catch(error \u003d\u003e { // Catch and log any errors during network request or parsing\n      console.error(\"Error fetching Gemini AI completion:\", error);\n      return [\"Error\", \"0\"];\n    });\n}\n"}]}
